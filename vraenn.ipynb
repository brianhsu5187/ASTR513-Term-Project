{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ebccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "421aef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, GRU, TimeDistributed\n",
    "# from keras.layers import Dense, concatenate\n",
    "# from keras.layers import RepeatVector, Lambda\n",
    "# from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import keras.backend as K\n",
    "# from keras.callbacks import EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "import logging\n",
    "from glob import glob\n",
    "# from keras.losses import mse\n",
    "# import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "now = datetime.datetime.now()\n",
    "date = str(now.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "\n",
    "NEURON_N_DEFAULT = 100\n",
    "ENCODING_N_DEFAULT = 10\n",
    "N_EPOCH_DEFAULT = 1000\n",
    "nfilts = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a011735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCurve(object):\n",
    "    \"\"\"Light Curve class\n",
    "    \"\"\"\n",
    "    def __init__(self, name, times, fluxes, flux_errs, filters,\n",
    "                 zpt=0, mwebv=0, redshift=None, redshift_err=None,\n",
    "                 lim_mag=None, obj_type=None):\n",
    "\n",
    "        self.name = name\n",
    "        self.times = times\n",
    "        self.fluxes = fluxes\n",
    "        self.flux_errs = flux_errs\n",
    "        self.filters = filters\n",
    "        self.zpt = zpt\n",
    "        self.mwebv = mwebv\n",
    "        self.redshift = redshift\n",
    "        self.redshift_err = redshift_err\n",
    "        self.lim_mag = lim_mag\n",
    "        self.obj_type = obj_type\n",
    "\n",
    "        self.abs_mags = None\n",
    "        self.abs_mags_err = None\n",
    "        self.abs_lim_mag = None\n",
    "\n",
    "    def sort_lc(self):\n",
    "        gind = np.argsort(self.times)\n",
    "        self.times = self.times[gind]\n",
    "        self.fluxes = self.fluxes[gind]\n",
    "        self.flux_errs = self.flux_errs[gind]\n",
    "        self.filters = self.filters[gind]\n",
    "        if self.abs_mags is not None:\n",
    "            self.abs_mags = self.abs_mags[gind]\n",
    "            self.abs_mags_err = self.abs_mags_err[gind]\n",
    "\n",
    "    def find_peak(self, tpeak_guess):\n",
    "        gind = np.where((np.abs(self.times-tpeak_guess) < 1000.0) &\n",
    "                        (self.fluxes/self.flux_errs > 3.0))\n",
    "        if len(gind[0]) == 0:\n",
    "            gind = np.where((np.abs(self.times - tpeak_guess) < 1000.0))\n",
    "        if len(gind[0]) == 0:\n",
    "            tpeak = tpeak_guess\n",
    "            return tpeak\n",
    "        if self.abs_mags is not None:\n",
    "            tpeak = self.times[gind][np.argmin(self.abs_mags[gind])]\n",
    "        return tpeak\n",
    "\n",
    "    def cut_lc(self, limit_before=100, limit_after=200):\n",
    "        gind = np.where((self.times > -limit_before) &\n",
    "                        (self.times < limit_after))\n",
    "        self.times = self.times[gind]\n",
    "        self.fluxes = self.fluxes[gind]\n",
    "        self.flux_errs = self.flux_errs[gind]\n",
    "        self.filters = self.filters[gind]\n",
    "        if self.abs_mags is not None:\n",
    "            self.abs_mags = self.abs_mags[gind]\n",
    "            self.abs_mags_err = self.abs_mags_err[gind]\n",
    "\n",
    "    def shift_lc(self, t0=0):\n",
    "        self.times = self.times - t0\n",
    "\n",
    "    def correct_time_dilation(self):\n",
    "        self.times = self.times / (1.+self.redshift)\n",
    "\n",
    "    def add_LC_info(self, zpt=27.5, mwebv=0.0, redshift=0.0,redshift_err=0.0,\n",
    "                    lim_mag=25.0, obj_type='-'):\n",
    "        self.zpt = zpt\n",
    "        self.mwebv = mwebv\n",
    "        self.redshift = redshift\n",
    "        self.redshift_err = redshift_err\n",
    "        self.lim_mag = lim_mag\n",
    "        self.obj_type = obj_type\n",
    "\n",
    "    def get_abs_mags(self, replace_nondetections=True, mag_err_fill=1.0):\n",
    "        \"\"\"\n",
    "        Convert flux into absolute magnitude\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        replace_nondetections : bool\n",
    "            Replace nondetections with limiting mag.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self.abs_mags : list\n",
    "            Absolute magnitudes\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        \"\"\"\n",
    "        lsst_filters = {'0':3740., '1':4870., '2':6250., '3':7700., '4':8900., '5':10845.}\n",
    "        ext = G23(Rv=3.1)\n",
    "        reddening = -2.5 * np.log10(ext.extinguish([lsst_filters[str(filt)] for filt \n",
    "                                                    in self.filters.astype(int)] * u.AA, \n",
    "                                                    Ebv=self.mwebv))\n",
    "        k_correction = 2.5 * np.log10(1.+self.redshift)\n",
    "        dist = cosmo.luminosity_distance([self.redshift]).value[0]  # returns dist in Mpc\n",
    "\n",
    "        self.abs_mags = -2.5 * np.log10(self.fluxes) + self.zpt - 5. * \\\n",
    "            np.log10(dist*1e6/10.0) + k_correction - reddening\n",
    "        self.abs_mags_err = np.abs((2.5/np.log(10))*(self.flux_errs/self.fluxes))\n",
    "\n",
    "        if replace_nondetections:\n",
    "            abs_lim_mag = self.lim_mag - 5.0 * np.log10(dist * 1e6 / 10.0) + \\\n",
    "                            k_correction\n",
    "            gind = np.where((np.isnan(self.abs_mags)) |\n",
    "                            np.isinf(self.abs_mags) |\n",
    "                            np.isnan(self.abs_mags_err) |\n",
    "                            np.isinf(self.abs_mags_err) |\n",
    "                            (self.abs_mags > self.lim_mag))\n",
    "\n",
    "            self.abs_mags[gind] = abs_lim_mag\n",
    "            self.abs_mags_err[gind] = mag_err_fill\n",
    "        self.abs_lim_mag = abs_lim_mag\n",
    "\n",
    "        return self.abs_mags, self.abs_mags_err\n",
    "\n",
    "    def make_dense_LC(self, nfilts=6):\n",
    "        gp_mags = self.abs_mags - self.abs_lim_mag\n",
    "        dense_fluxes = np.zeros((len(self.times), nfilts))\n",
    "        dense_errs = np.zeros((len(self.times), nfilts))\n",
    "        stacked_data = np.vstack([self.times, self.filters]).T\n",
    "        x_pred = np.zeros((len(self.times)*nfilts, 2))\n",
    "        print(self.name)\n",
    "\n",
    "        pred, pred_var, gp, times = run_gp(self.times, self.filters, gp_mags, self.abs_mags_err)\n",
    "        pred = pred.T\n",
    "        pred_var = pred_var.T\n",
    "        self.gp = [1,2,3]\n",
    "\n",
    "        dense_fluxes = pred + self.abs_lim_mag\n",
    "        dense_errs = np.sqrt(pred_var)\n",
    "\n",
    "        self.dense_lc = np.dstack((dense_fluxes, dense_errs))\n",
    "        self.dense_times = times\n",
    "\n",
    "        self.gp_mags = gp_mags\n",
    "        return gp, gp_mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebd0d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input(input_lc_file, new_t_max=100.0, filler_err=1.0,\n",
    "               save=False, load=False, outdir=None, prep_file=None):\n",
    "    \"\"\"\n",
    "    Prep input file for fitting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_lc_file : str\n",
    "        True flux values\n",
    "    new_t_max : float\n",
    "        Predicted flux values\n",
    "    filler_err : float\n",
    "        Predicted flux values\n",
    "    save : bool\n",
    "        Predicted flux values\n",
    "    load : bool\n",
    "        Predicted flux values\n",
    "    outdir : str\n",
    "        Predicted flux values\n",
    "    prep_file : str\n",
    "        Predicted flux values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sequence : numpy.ndarray\n",
    "        Array LC flux times, values and errors\n",
    "    outseq : numpy.ndarray\n",
    "        An array of LC flux values and limiting magnitudes\n",
    "    ids : numpy.ndarray\n",
    "        Array of SN names\n",
    "    sequence_len : float\n",
    "        Maximum length of LC values\n",
    "    nfilts : int\n",
    "        Number of filters in LC files\n",
    "    \"\"\"\n",
    "    lightcurves = np.load('preprocessed_lc/lcs.npz', allow_pickle=True)['lcs']\n",
    "    lengths = []\n",
    "    ids = []\n",
    "    gind = []\n",
    "    for j,lightcurve in enumerate(lightcurves):\n",
    "        if type(lightcurve) == float:\n",
    "            continue\n",
    "        gind.append(j)\n",
    "        lengths.append(len(lightcurve.times))\n",
    "        ids.append(lightcurve.name)\n",
    "    lightcurves = lightcurves[gind]\n",
    "    sequence_len = np.max(lengths)\n",
    "    nfilts = np.shape(lightcurves[0].dense_lc)[1]\n",
    "    nfiltsp1 = nfilts+1\n",
    "    n_lcs = len(lightcurves)\n",
    "    # convert from LC format to list of arrays\n",
    "    sequence = np.zeros((n_lcs, sequence_len, nfilts*2+1))\n",
    "\n",
    "    lms = []\n",
    "    for i, lightcurve in enumerate(lightcurves):\n",
    "        sequence[i, 0:lengths[i], 0] = lightcurve.times\n",
    "        pred = []\n",
    "        for j in range(6):\n",
    "            pred.append(np.interp(lightcurve.times, lightcurve.dense_times, lightcurve.dense_lc[:, :, 0].T[j]))\n",
    "        pred = np.array(pred).T\n",
    "        sequence[i, 0:lengths[i], 1:nfiltsp1] = pred\n",
    "        err_pred = []\n",
    "        for j in range(6):\n",
    "            err_pred.append(np.interp(lightcurve.times, lightcurve.dense_times, lightcurve.dense_lc[:, :, 1].T[j]))\n",
    "        err_pred = np.array(err_pred).T\n",
    "        sequence[i, 0:lengths[i], nfiltsp1:] = err_pred + 0.01\n",
    "        sequence[i, lengths[i]:, 0] = np.max(lightcurve.times)+new_t_max\n",
    "        sequence[i, lengths[i]:, 1:nfiltsp1] = lightcurve.abs_lim_mag\n",
    "        sequence[i, lengths[i]:, nfiltsp1:] = filler_err\n",
    "        lms.append(lightcurve.abs_lim_mag)\n",
    "\n",
    "    # Flip because who needs negative magnitudes\n",
    "    sequence[:, :, 1:nfiltsp1] = -1.0 * sequence[:, :, 1:nfiltsp1]\n",
    "\n",
    "    if load:\n",
    "        prep_data = np.load(prep_file)\n",
    "        bandmin = prep_data['bandmin']\n",
    "        bandmax = prep_data['bandmax']\n",
    "    else:\n",
    "        bandmin = np.min(sequence[:, :, 1:nfiltsp1])\n",
    "        bandmax = np.max(sequence[:, :, 1:nfiltsp1])\n",
    "\n",
    "    sequence[:, :, 1:nfiltsp1] = (sequence[:, :, 1:nfiltsp1] - bandmin) \\\n",
    "        / (bandmax - bandmin)\n",
    "    #sequence[:, :, nfiltsp1:] = sequence[:, :, nfiltsp1:] \\\n",
    "     #   / (bandmax - bandmin)\n",
    "\n",
    "    new_lms = np.reshape(np.repeat(lms, sequence_len), (len(lms), -1))\n",
    "\n",
    "    outseq = np.reshape(sequence[:, :, 0], (len(sequence), sequence_len, 1)) * 1.0\n",
    "    outseq = np.dstack((outseq, new_lms))\n",
    "    if save:\n",
    "        model_prep_file = outdir+'prep_'+date+'.npz'\n",
    "        np.savez(model_prep_file, bandmin=bandmin, bandmax=bandmax)\n",
    "        model_prep_file = outdir+'prep.npz'\n",
    "        np.savez(model_prep_file, bandmin=bandmin, bandmax=bandmax)\n",
    "    return sequence, outseq, ids, sequence_len, nfilts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(yTrue, yPred):\n",
    "    \"\"\"\n",
    "    Custom loss which doesn't use the errors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yTrue : array\n",
    "        True flux values\n",
    "    yPred : array\n",
    "        Predicted flux values\n",
    "    \"\"\"\n",
    "\n",
    "    global nfilts\n",
    "    return K.mean(K.square(yTrue[:, :, 1:(1+nfilts)] - yPred[:, :, :])/K.square(yTrue[:,:,(1+nfilts):]))\n",
    "    #return K.mean(K.square(yTrue[:, :, 1:(1+nfilts)] - yPred[:, :, :]))\n",
    "    \n",
    "def vae_loss(encoded_mean, encoded_log_sigma):\n",
    "    global nfilts\n",
    "\n",
    "    kl_loss = - 0.5 * K.mean(1 + encoded_log_sigma - K.square(encoded_mean) - K.exp(encoded_log_sigma), axis=-1)\n",
    "\n",
    "    def lossFunction(yTrue,yPred):   \n",
    "        #reconstruction_loss = K.mean(K.square(yTrue[:, :, 1:(1+nfilts)] - yPred[:, :, :])/K.square(yTrue[:,:,(1+nfilts):]))\n",
    "        reconstruction_loss = K.log(K.mean(K.square(yTrue[:, :, 1:(1+nfilts)] - yPred[:, :, :])))\n",
    "\n",
    "        return reconstruction_loss + kl_loss\n",
    "\n",
    "    return lossFunction\n",
    "\n",
    "\n",
    "\n",
    "def sampling(samp_args):\n",
    "    z_mean, z_log_sigma = samp_args\n",
    "\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "\n",
    "def make_model(LSTMN, encodingN, maxlen, nfilts, sequence, outseq):\n",
    "    \"\"\"\n",
    "    Make RAENN model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    LSTMN : int\n",
    "        Number of neurons to use in first/last layers\n",
    "    encodingN : int\n",
    "        Number of neurons to use in encoding layer\n",
    "    maxlen : int\n",
    "        Maximum LC length\n",
    "    nfilts : int\n",
    "        Number of filters in LCs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.models.Model\n",
    "        RAENN model to be trained\n",
    "    callbacks_list : list\n",
    "        List of keras callbacks\n",
    "    input_1 : keras.layer\n",
    "        Input layer of RAENN\n",
    "    encoded : keras.layer\n",
    "        RAENN encoding layer\n",
    "    \"\"\"\n",
    "\n",
    "    input_1 = Input((None, nfilts*2+1))\n",
    "    input_2 = Input((maxlen, 2))\n",
    "\n",
    "    encoder1 = GRU(LSTMN, return_sequences=True, activation='tanh', recurrent_activation='hard_sigmoid')(input_1)\n",
    "    encoder2 = GRU(LSTMN, return_sequences=True, activation='relu', recurrent_activation='hard_sigmoid')(encoder1)\n",
    "    encoded_mean = GRU(encodingN, return_sequences=False, activation='linear')(encoder2)\n",
    "    encoded_log_sigma = GRU(encodingN, return_sequences=False, activation='linear')(encoder2)\n",
    "    z = Lambda(sampling, output_shape=(encodingN,))([encoded_mean, encoded_log_sigma])\n",
    "\n",
    "    repeater = RepeatVector(maxlen)(z)\n",
    "    merged = concatenate([repeater, input_2], axis=-1)\n",
    "    decoder1 = GRU(LSTMN, return_sequences=True, activation='tanh', recurrent_activation='hard_sigmoid')(merged)\n",
    "    decoder2 = GRU(LSTMN, return_sequences=True, activation='tanh', recurrent_activation='hard_sigmoid')(decoder1)\n",
    "    decoder3 = TimeDistributed(Dense(nfilts, activation='tanh'),\n",
    "                               input_shape=(None, 1))(decoder2)\n",
    "\n",
    "    model = Model([input_1, input_2], decoder3)\n",
    "\n",
    "    new_optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999,\n",
    "                         decay=0)\n",
    "    #model.compile(optimizer=new_optimizer, loss=customLoss)\n",
    "    model.compile(optimizer = new_optimizer, \n",
    "        loss = vae_loss(encoded_mean,encoded_log_sigma))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=50,\n",
    "                       verbose=0, mode='min', baseline=None,\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "    callbacks_list = [es]\n",
    "    return model, callbacks_list, input_1, encoded_mean, encoded_log_sigma\n",
    "\n",
    "\n",
    "def fit_model(model, callbacks_list, sequence, outseq, n_epoch):\n",
    "    \"\"\"\n",
    "    Make RAENN model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.models.Model\n",
    "        RAENN model to be trained\n",
    "    callbacks_list : list\n",
    "        List of keras callbacks\n",
    "    sequence : numpy.ndarray\n",
    "        Array LC flux times, values and errors\n",
    "    outseq : numpy.ndarray\n",
    "        An array of LC flux values and limiting magnitudes\n",
    "    n_epoch : int\n",
    "        Number of epochs to train for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.models.Model\n",
    "        Trained keras model\n",
    "    \"\"\"\n",
    "    model.fit([sequence, outseq], sequence, epochs=n_epoch,  verbose=1,\n",
    "              shuffle=False, callbacks=callbacks_list, validation_split=0.33)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(sequence_test, model, lms, sequence_len, plot=True):\n",
    "    outseq_test = np.reshape(sequence_test[:, :, 0], (len(sequence_test), sequence_len, 1))\n",
    "    lms_test = np.reshape(np.repeat([lms], sequence_len), (len(sequence_test), -1))\n",
    "    outseq_test = np.reshape(outseq_test[:, :, 0], (len(sequence_test), sequence_len, 1))\n",
    "    outseq_test = np.dstack((outseq_test, lms_test))\n",
    "\n",
    "    yhat = model.predict([sequence_test, outseq_test], verbose=1)\n",
    "    if plot:\n",
    "        plt.plot(sequence_test[0, :, 0], yhat[0, :, 1], color='grey')\n",
    "        plt.plot(sequence_test[0, :, 0], sequence_test[0, :, 2], color='grey')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def get_encoder(model, input_1, encoded, encoded_err):\n",
    "    encoder = Model(input_1, encoded)\n",
    "    encoder_err = Model(input_1,encoded_err)\n",
    "    return encoder, encoder_err\n",
    "\n",
    "\n",
    "def get_decoder(model, encodingN):\n",
    "    encoded_input = Input(shape=(None, (encodingN+2)))\n",
    "    decoder_layer2 = model.layers[-2]\n",
    "    decoder_layer3 = model.layers[-1]\n",
    "    decoder = Model(encoded_input, decoder_layer3(decoder_layer2(encoded_input)))\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def get_decodings(decoder, encoder, sequence, lms, encodingN, sequence_len,\n",
    "                nfilts, ids, plot=True):\n",
    "    if plot:\n",
    "        for i in np.arange(len(sequence)):\n",
    "            seq = np.reshape(sequence[i, :, :], (1, sequence_len, (nfilts*2+1)))\n",
    "            encoding1 = encoder.predict(seq)[-1]\n",
    "            encoding1 = np.vstack([encoding1]).reshape((1, 1, encodingN))\n",
    "            repeater1 = np.repeat(encoding1, sequence_len, axis=1)\n",
    "            out_seq = np.reshape(seq[:, :, 0], (len(seq), sequence_len, 1))\n",
    "            lms_test = np.reshape(np.repeat(lms[i], sequence_len), (len(seq), -1))\n",
    "            out_seq = np.dstack((out_seq, lms_test))\n",
    "\n",
    "            decoding_input2 = np.concatenate((repeater1, out_seq), axis=-1)\n",
    "\n",
    "            decoding2 = decoder.predict(decoding_input2)[0]\n",
    "\n",
    "            plt.plot(seq[0, :, 0], seq[0, :, 1], 'o',color='green', alpha=1.0, linewidth=1)\n",
    "            plt.plot(seq[0, :, 0], decoding2[:, 0], 'green', alpha=0.2, linewidth=10)\n",
    "            plt.plot(seq[0, :, 0], seq[0, :, 2], 'o',color='red', alpha=1.0, linewidth=1)\n",
    "            plt.plot(seq[0, :, 0], decoding2[:, 1], 'red', alpha=0.2, linewidth=10)\n",
    "            plt.title(ids[i])\n",
    "            #plt.plot(seq[0, :, 0], seq[0, :, 3], 'orange', alpha=1.0, linewidth=1)\n",
    "            #plt.plot(seq[0, :, 0], decoding2[:, 2], 'orange', alpha=0.2, linewidth=10)\n",
    "            #plt.plot(seq[0, :, 0], seq[0, :, 4], 'purple', alpha=1.0, linewidth=1)\n",
    "            #plt.plot(seq[0, :, 0], decoding2[:, 3], 'purple', alpha=0.2, linewidth=10)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def save_model(model, encodingN, LSTMN, model_dir='models/', outdir='./'):\n",
    "    # make output dir\n",
    "    model_dir = outdir + model_dir\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_dir+\"model_\"+date+\"_\"+str(encodingN)+'_'+str(LSTMN)+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    with open(model_dir+\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_dir+\"model_\"+date+\"_\"+str(encodingN)+'_'+str(LSTMN)+\".h5\")\n",
    "    model.save_weights(model_dir+\"model.h5\")\n",
    "\n",
    "    logging.info(f'Saved model to {model_dir}')\n",
    "\n",
    "\n",
    "def save_encodings(model, encoder, encoder_err, sequence, ids, INPUT_FILE,\n",
    "                   encodingN, LSTMN, N, sequence_len,nfilts,\n",
    "                   model_dir='encodings/', outdir='./'):\n",
    "\n",
    "    # Make output directory\n",
    "    model_dir = outdir + model_dir\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    encodings = np.zeros((N, encodingN))\n",
    "    encodings_err = np.zeros((N, encodingN))\n",
    "\n",
    "    for i in np.arange(N):\n",
    "        seq = np.reshape(sequence[i, :, :], (1, sequence_len, (nfilts*2+1)))\n",
    "\n",
    "        my_encoding = encoder.predict(seq)\n",
    "        my_encoding_err = encoder_err.predict(seq)\n",
    "\n",
    "        encodings[i, :] = my_encoding\n",
    "        encodings_err[i, :] = my_encoding_err\n",
    "\n",
    "        encoder.reset_states()\n",
    "        encoder_err.reset_states()\n",
    "\n",
    "    encoder_sne_file = model_dir+'en_'+date+'_'+str(encodingN)+'_'+str(LSTMN)+'.npz'\n",
    "    np.savez(encoder_sne_file, encodings=encodings, encoding_errs = encodings_err, ids=ids, INPUT_FILE=INPUT_FILE)\n",
    "    np.savez(model_dir+'en.npz', encodings=encodings, encoding_errs = encodings_err, ids=ids, INPUT_FILE=INPUT_FILE)\n",
    "\n",
    "    logging.info(f'Saved encodings to {model_dir}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('lcfile', type=str, help='Light curve file')\n",
    "    parser.add_argument('--outdir', type=str, default='./products/',\n",
    "                        help='Path in which to save the LC data (single file)')\n",
    "    parser.add_argument('--plot', type=bool, default=False, help='Plot LCs')\n",
    "    parser.add_argument('--neuronN', type=int, default=NEURON_N_DEFAULT, help='Number of neurons in hidden layers')\n",
    "    parser.add_argument('--encodingN', type=int, default=ENCODING_N_DEFAULT,\n",
    "                        help='Number of neurons in encoding layer')\n",
    "    parser.add_argument('--n-epoch', type=int, dest='n_epoch',\n",
    "                        default=N_EPOCH_DEFAULT,\n",
    "                        help='Number of epochs to train for')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    global nfilts\n",
    "\n",
    "    sequence, outseq, ids, maxlen, nfilts = prep_input(args.lcfile, save=True, outdir=args.outdir)\n",
    "    if args.plot:\n",
    "        for s in sequence:\n",
    "            plt.plot(s[:, 0], s[:, 1])\n",
    "            plt.plot(s[:, 0], s[:, 2])\n",
    "            plt.plot(s[:, 0], s[:, 3])\n",
    "            plt.plot(s[:, 0], s[:, 4])\n",
    "            plt.show()\n",
    "\n",
    "    model, callbacks_list, input_1, encoded, encoded_err = make_model(args.neuronN,\n",
    "                                                         args.encodingN,\n",
    "                                                         maxlen, nfilts, sequence, outseq)\n",
    "    model = fit_model(model, callbacks_list, sequence, outseq, args.n_epoch)\n",
    "    encoder, encoder_err = get_encoder(model, input_1, encoded, encoded_err)\n",
    "\n",
    "    # These comments used in testing, and sould be removed...\n",
    "    # lms = outseq[:, 0, 1]\n",
    "    # test_model(sequence_test, model, lm, maxlen, plot=True)\n",
    "    # decoder = get_decoder(model, args.encodingN)\n",
    "    # get_decodings(decoder, encoder, sequence, lms, args.encodingN, \\\n",
    "    #               maxlen, plot=False)\n",
    "\n",
    "    if args.outdir[-1] != '/':\n",
    "        args.outdir += '/'\n",
    "    save_model(model, args.encodingN, args.neuronN, outdir=args.outdir)\n",
    "\n",
    "    save_encodings(model, encoder, encoder_err, sequence, ids, args.lcfile,\n",
    "                   args.encodingN, args.neuronN, len(ids), maxlen,nfilts,\n",
    "                   outdir=args.outdir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
